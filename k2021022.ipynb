{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028a81b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ID'] = 'PCI_BUS_ORDER'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbedd4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "MNIST    = 'mnist'        # https://en.wikipedia.org/wiki/MNIST_database\n",
    "F_MNIST  = 'fashion_mnist' # https://github.com/zalandoresearch/fashion-mnist\n",
    "CIPHAR10 = 'ciphar10'     # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "DATA_NAME = MNIST \n",
    "\n",
    "\n",
    "DATA_DIR = f'data/{DATA_NAME}'\n",
    "GEN_DIR = f'gen_images_{DATA_NAME}'\n",
    "os.makedirs(GEN_DIR, exist_ok=True)\n",
    "\n",
    "print(f'torch.version:{torch.__version__}')\n",
    "print(f'cuda:{cuda}')\n",
    "\n",
    "\n",
    "!python --version\n",
    "!pwd\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41302cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_channel = {MNIST:1, F_MNIST:1, CIPHAR10:3}[DATA_NAME]\n",
    "img_size =  {MNIST:28, F_MNIST:28, CIPHAR10:32}[DATA_NAME]\n",
    "VISION_DATASET =  {MNIST:datasets.MNIST, F_MNIST:datasets.FashionMNIST, CIPHAR10:datasets.CIFAR10}[DATA_NAME]\n",
    "\n",
    "class Option:\n",
    "    def __init__(self):\n",
    "        self.n_epochs = 50         # number of epochs of training\n",
    "        self.batch_size = 64       # size of the batches\n",
    "        self.lr = 0.0002           # adam: learning rate\n",
    "        self.b1 = 0.5              # adam: decay of first order momentum of gradient\n",
    "        self.b2 = 0.999            # adam: decay of first order momentum of gradient\n",
    "        self.n_cpu = 2             # number of cpu threads to use during batch generation\n",
    "        self.latent_dim = 100      # dimensionality of the latent space\n",
    "        self.n_classes = 10        # number of classes for dataset\n",
    "        self.img_size = img_size   # size of each image dimension\n",
    "        self.channels = n_channel  # number of image channels\n",
    "        self.sample_interval = 400 # interval between image sampling\")\n",
    "        \n",
    "opt = Option()\n",
    "vars(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade0b68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042761c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim + opt.n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "    \n",
    "# Create generator \n",
    "generator = Generator()\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05ca07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "\n",
    "# Create discriminator\n",
    "discriminator = Discriminator()\n",
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7c180",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3363b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "ds = VISION_DATASET(DATA_DIR, train=True,download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), \n",
    "             transforms.ToTensor(), \n",
    "             transforms.Normalize([0.5], [0.5])\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcf460",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    img, label =  random.choice(ds)\n",
    "    img = ((img + 1)/2*255).type(torch.uint8).permute((1,2,0)).squeeze()\n",
    "    print(f'[{label}] {ds.classes[label]}')\n",
    "    display(Image.fromarray(img.numpy()).resize((128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8890f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864ba84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "def sample_image(n_width, epoch, n_label = 10):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = torch.Tensor(np.random.normal(0, 1, (n_width* n_label, opt.latent_dim))).type(FloatTensor)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([label for label in range(n_label) for _ in range(n_width)])\n",
    "    labels = torch.Tensor(labels).type(LongTensor)\n",
    "    gen_imgs = generator(z, labels)\n",
    "    img_path = f\"{GEN_DIR}/{epoch:06d}.png\"\n",
    "    save_image(gen_imgs.data, img_path, nrow=n_width, normalize=True)\n",
    "    return img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8731d55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    print(f'{epoch+1}/{opt.n_epochs}')\n",
    "    if epoch:\n",
    "        print(f'D loss: {d_loss.item():.04f},  G loss: {g_loss.item()}')\n",
    "        display(Image.open(img_path))\n",
    "        \n",
    "        \n",
    "    for i, (imgs, labels) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = FloatTensor(batch_size, 1).fill_(1.0)\n",
    "        fake  = FloatTensor(batch_size, 1).fill_(0.0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.type(FloatTensor)\n",
    "        labels = labels.type(LongTensor)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim)))\n",
    "        gen_labels = LongTensor(np.random.randint(0, opt.n_classes, batch_size))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    img_path = sample_image(n_width=30, epoch=epoch, n_label=opt.n_classes)\n",
    "    ipd.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c54ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stylegan3]",
   "language": "python",
   "name": "conda-env-stylegan3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.74273,
   "end_time": "2022-04-12T09:35:30.260686",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T09:35:29.517956",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
